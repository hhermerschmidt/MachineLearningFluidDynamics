% Encoding: UTF-8

@Article{Genzel2019,
  author     = {Martin Genzel and Gitta Kutyniok},
  journal    = {GAMM Rundbrief},
  title      = {Artificial Neural Networks},
  year       = {2019},
  pages      = {12-18},
  volume     = {2},
  file       = {:GenzelEtAl_2019_ArtificialNeuralNetworks.pdf:PDF;:GenzelEtAl_2019_ArtificialNeuralNetworks_notes.pdf:PDF},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020.04.23},
}

@Book{Goodfellow2016,
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  publisher = {MIT Press},
  title     = {Deep Learning},
  year      = {2016},
  note      = {\url{http://www.deeplearningbook.org}},
  file      = {:GoodfellowEtAl_2016_DeepLearning.pdf:PDF},
  timestamp = {2020.04.29},
}

@Article{LeCun2015,
  author    = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
  journal   = {Nature},
  title     = {Deep Learning},
  year      = {2015},
  month     = {05},
  pages     = {436-44},
  volume    = {521},
  doi       = {10.1038/nature14539},
  file      = {:LeCunEtAl_2018_DeepLearning.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.04.29},
}

@Misc{Fan2019,
  author        = {Jianqing Fan and Cong Ma and Yiqiao Zhong},
  title         = {A Selective Overview of Deep Learning},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1904.05526},
  file          = {:FanEtAl_2019_SelectiveOverviewDeepLearning.pdf:PDF},
  groups        = {Neural Networks},
  primaryclass  = {stat.ML},
  timestamp     = {2020.04.29},
}

@Article{Lagaris1998,
  author    = {Lagaris, Isaac and Likas, Aristidis and Fotiadis, Dimitrios},
  journal   = {IEEE Transactions on Neural Networks},
  title     = {Artificial neural networks for solving ordinary and partial differential equations},
  year      = {1998},
  month     = {09},
  pages     = {987-1000},
  volume    = {9},
  doi       = {10.1109/72.712178},
  file      = {:LagarisEtAl_1998_ANNSolvingODEPDE.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.04.29},
}

@Misc{Higham2018,
  author        = {Catherine F. Higham and Desmond J. Higham},
  title         = {Deep Learning: An Introduction for Applied Mathematicians},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1801.05894},
  file          = {:HighamEtAl_2018_DeepLearningIntroAppliedMathematics.pdf:PDF},
  groups        = {Neural Networks},
  primaryclass  = {math.HO},
  timestamp     = {2020.04.29},
}

@InProceedings{Zhang2020,
  author    = {Mingrui Zhang and Matthew D. Piggott},
  booktitle = {2020 International Conference on High Performance Computing Simulation (HPCS)},
  title     = {Unsupervised Learning of Particle Image Velocimetry},
  year      = {2020},
  file      = {:ZhangEtAl_UnsupervisedLearningPIV.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Proceedings{ISCHPC2020,
  title     = {International Supercomputing Conference (ISC) High Performance 2020 Digital},
  year      = {2020},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@InProceedings{Harel2020,
  author    = {Re'em Harel and Matan Rusanovsky and Yehonatan Fridman and Assaf Shimony and Gal Oren},
  booktitle = {2020 International Conference on High Performance Computing Simulation (HPCS)},
  title     = {Complete Deep Computer-Vision Methodology for Investigating Hydrodynamic Instabilities},
  year      = {2020},
  file      = {:HarelEtAl_DeepCompVisionMethodologyHydrodynamicInstabilities.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@InProceedings{Nogueira2020,
  author    = {Alberto Costa Nogueira and Joao Lucas de Sousa Almeida and Guillaume Auger and Campbell D. Watson},
  booktitle = {2020 International Conference on High Performance Computing Simulation (HPCS)},
  title     = {First International Workshop on the Application of Machine Learning Techniques to Computational Fluid Dynamics Simulations and Analysis},
  year      = {2020},
  file      = {:CostaEtAl_ROMDynSysANNWaterCirculation.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@InProceedings{Luo2020,
  author    = {Shirui Luo and Madhu Vellakal and Seid Koric and Volodymyr Kindratenko and Jiahuan Cui},
  booktitle = {2020 International Conference on High Performance Computing Simulation (HPCS)},
  title     = {Parameter Identification of RANS Turbulence Model using Physics-embedded Neural Network},
  year      = {2020},
  file      = {:LuoEtAl_RANSPhysicsEmbededNN.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Mao2020,
  author    = {Zhiping Mao and Ameya D. Jagtap and George Em Karniadakis},
  journal   = {Computer Methods in Applied Mechanics and Engineering},
  title     = {Physics-informed neural networks for high-speed flows},
  year      = {2020},
  issn      = {0045-7825},
  pages     = {112789},
  volume    = {360},
  abstract  = {In this work we investigate the possibility of using physics-informed neural networks (PINNs) to approximate the Euler equations that model high-speed aerodynamic flows. In particular, we solve both the forward and inverse problems in one-dimensional and two-dimensional domains. For the forward problem, we utilize the Euler equations and the initial/boundary conditions to formulate the loss function, and solve the one-dimensional Euler equations with smooth solutions and with solutions that have a contact discontinuity as well as a two-dimensional oblique shock wave problem. We demonstrate that we can capture the solutions with only a few scattered points clustered randomly around the discontinuities. For the inverse problem, motivated by mimicking the Schlieren photography experimental technique used traditionally in high-speed aerodynamics, we use the data on density gradient ∇ρ(x,t), the pressure p(x∗,t) at a specified point x=x∗ as well as the conservation laws to infer all states of interest (density, velocity and pressure fields). We present illustrative benchmark examples for both the problem with smooth solutions and Riemann problems (Sod and Lax problems) with PINNs, demonstrating that all inferred states are in good agreement with the reference solutions. Moreover, we show that the choice of the position of the point x∗ plays an important role in the learning process. In particular, for the problem with smooth solutions we can randomly choose the position of the point x∗ from the computational domain, while for the Sod or Lax problem, we have to choose the position of the point x∗ from the domain between the initial discontinuous point and the shock position of the final time. We also solve the inverse problem by combining the aforementioned data and the Euler equations in characteristic form, showing that the results obtained by using the Euler equations in characteristic form are better than that obtained by using the Euler equations in conservative form. Furthermore, we consider another type of inverse problem, specifically, we employ PINNs to learn the value of the parameter γ in the equation of state for the parameterized two-dimensional oblique wave problem by using the given data of the density, velocity and the pressure, and we identify the parameter γ accurately. Taken together, our results demonstrate that in the current form, where the conservation laws are imposed at random points, PINNs are not as accurate as traditional numerical methods for forward problems but they are superior for inverse problems that cannot even be solved with standard techniques.},
  doi       = {https://doi.org/10.1016/j.cma.2019.112789},
  file      = {:MaoEtAl_2020_PhysicsInformedNNHighSpeedFlows.pdf:PDF},
  groups    = {Neural Networks},
  keywords  = {Euler equations, Machine learning, Neural networks, Conservation laws, Riemann problem, Hidden fluid mechanics},
  timestamp = {2020.06.30},
  url       = {http://www.sciencedirect.com/science/article/pii/S0045782519306814},
}

@Article{Lu2019,
  author        = {Lu Lu and Xuhui Meng and Zhiping Mao and George E. Karniadakis},
  journal       = {CoRR},
  title         = {DeepXDE: {A} deep learning library for solving differential equations},
  year          = {2019},
  volume        = {abs/1907.04502},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1907-04502.bib},
  eprint        = {1907.04502},
  file          = {:LuEtAl_2020_DeepXDE.pdf:PDF},
  groups        = {Neural Networks},
  timestamp     = {2020.06.30},
  url           = {http://arxiv.org/abs/1907.04502},
}

@InProceedings{Benzi2017,
  author    = {R. {Benzi} and L. {Biferale} and F. {Bonaccorso} and H. J. H. {Clercx} and A. {Corbetta} and W. {Möbius} and F. {Toschi} and F. {Salvadore} and C. {Cacciari} and G. {Erbacci}},
  booktitle = {2017 International Conference on High Performance Computing Simulation (HPCS)},
  title     = {TurBase: A Software Platform for Research in Experimental and Numerical Fluid Dynamics},
  year      = {2017},
  pages     = {51-57},
  file      = {:BenziEtAl_2017_TurBase.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Nabian2018,
  author        = {Mohammad Amin Nabian and Hadi Meidani},
  journal       = {CoRR},
  title         = {A Deep Neural Network Surrogate for High-Dimensional Random Partial Differential Equations},
  year          = {2018},
  volume        = {abs/1806.02957},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1806-02957.bib},
  eprint        = {1806.02957},
  file          = {:NabianEtAl_2018_DeepNNSurrogateHighDimRandomPDEs.pdf:PDF},
  groups        = {Neural Networks},
  timestamp     = {2020.06.30},
  url           = {http://arxiv.org/abs/1806.02957},
}

@Article{Nabian2018a,
  author        = {Mohammad Amin Nabian and Hadi Meidani},
  journal       = {CoRR},
  title         = {Physics-Informed Regularization of Deep Neural Networks},
  year          = {2018},
  volume        = {abs/1810.05547},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1810-05547.bib},
  eprint        = {1810.05547},
  file          = {:NabianEtAl_2019_PhysicsDrivenRegularizationDeepNN.pdf:PDF},
  groups        = {Neural Networks},
  timestamp     = {2020.06.30},
  url           = {http://arxiv.org/abs/1810.05547},
}

@Article{Raissi2017,
  author        = {Maziar Raissi and George E. Karniadakis},
  journal       = {CoRR},
  title         = {Hidden Physics Models: Machine Learning of Nonlinear Partial Differential Equations},
  year          = {2017},
  volume        = {abs/1708.00588},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1708-00588.bib},
  eprint        = {1708.00588},
  file          = {:RaissiEtAl_2017_HiddenPhysicsModelsMLNonlinearPDEs.pdf:PDF},
  groups        = {Neural Networks},
  timestamp     = {2020.06.30},
  url           = {http://arxiv.org/abs/1708.00588},
}

@Article{Raissi2017a,
  author        = {Maziar Raissi and Paris Perdikaris and George E. Karniadakis},
  journal       = {CoRR},
  title         = {Physics Informed Deep Learning (Part {I):} Data-driven Solutions of Nonlinear Partial Differential Equations},
  year          = {2017},
  volume        = {abs/1711.10561},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1711-10561.bib},
  eprint        = {1711.10561},
  file          = {:RaissiEtAl_2017_PhysicsInformedDeepLearning1.pdf:PDF},
  groups        = {Neural Networks},
  timestamp     = {2020.06.30},
  url           = {http://arxiv.org/abs/1711.10561},
}

@Article{Raissi2017b,
  author        = {Maziar Raissi and Paris Perdikaris and George E. Karniadakis},
  journal       = {CoRR},
  title         = {Physics Informed Deep Learning (Part {II):} Data-driven Discovery of Nonlinear Partial Differential Equations},
  year          = {2017},
  volume        = {abs/1711.10566},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1711-10566.bib},
  eprint        = {1711.10566},
  file          = {:RaissiEtAl_2017_PhysicsInformedDeepLearning2.pdf:PDF},
  groups        = {Neural Networks},
  timestamp     = {2020.06.30},
  url           = {http://arxiv.org/abs/1711.10566},
}

@Article{Sirignano2018,
  author    = {Justin Sirignano and Konstantinos Spiliopoulos},
  journal   = {Journal of Computational Physics},
  title     = {DGM: A deep learning algorithm for solving partial differential equations},
  year      = {2018},
  issn      = {0021-9991},
  pages     = {1339 - 1364},
  volume    = {375},
  abstract  = {High-dimensional PDEs have been a longstanding computational challenge. We propose to solve high-dimensional PDEs by approximating the solution with a deep neural network which is trained to satisfy the differential operator, initial condition, and boundary conditions. Our algorithm is meshfree, which is key since meshes become infeasible in higher dimensions. Instead of forming a mesh, the neural network is trained on batches of randomly sampled time and space points. The algorithm is tested on a class of high-dimensional free boundary PDEs, which we are able to accurately solve in up to 200 dimensions. The algorithm is also tested on a high-dimensional Hamilton–Jacobi–Bellman PDE and Burgers' equation. The deep learning algorithm approximates the general solution to the Burgers' equation for a continuum of different boundary conditions and physical conditions (which can be viewed as a high-dimensional space). We call the algorithm a “Deep Galerkin Method (DGM)” since it is similar in spirit to Galerkin methods, with the solution approximated by a neural network instead of a linear combination of basis functions. In addition, we prove a theorem regarding the approximation power of neural networks for a class of quasilinear parabolic PDEs.},
  doi       = {https://doi.org/10.1016/j.jcp.2018.08.029},
  file      = {:SirignanoEtAl_2018_DGM.pdf:PDF},
  groups    = {Neural Networks},
  keywords  = {Partial differential equations, Machine learning, Deep learning, High-dimensional partial differential equations},
  timestamp = {2020.06.30},
  url       = {http://www.sciencedirect.com/science/article/pii/S0021999118305527},
}

@Article{Brunton2020,
  author     = {Brunton, Steven L. and Noack, Bernd R. and Koumoutsakos, Petros},
  journal    = {Annual Review of Fluid Mechanics},
  title      = {Machine Learning for Fluid Mechanics},
  year       = {2020},
  number     = {1},
  pages      = {477-508},
  volume     = {52},
  abstract   = {The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract information from data that can be translated into knowledge about the underlying fluid mechanics. Moreover, ML algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of ML for fluid mechanics. We outline fundamental ML methodologies and discuss their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experiments, and simulations. ML provides a powerful information-processing framework that can augment, and possibly even transform, current lines of fluid mechanics research and industrial applications.},
  doi        = {10.1146/annurev-fluid-010719-060214},
  eprint     = {https://doi.org/10.1146/annurev-fluid-010719-060214},
  file       = {:BruntonEtAl_2020_MLFluidMechanics.pdf:PDF},
  groups     = {Neural Networks},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020.06.30},
  url        = {https://doi.org/10.1146/annurev-fluid-010719-060214},
}

@Article{Gonzalez2018,
  author    = {Francisco J. Gonzalez and Maciej Balajewicz},
  journal   = {ArXiv},
  title     = {Deep convolutional recurrent autoencoders for learning low-dimensional feature dynamics of fluid systems},
  year      = {2018},
  volume    = {abs/1808.01346},
  file      = {:GonzalezEtAl_2018_DeepConvolutionalRecurrentAutoEncodersLowDimFeatureDynamicsFluidSystems.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Kim2018,
  author        = {Byungsoo Kim and Vinicius C. Azevedo and Nils Thuerey and Theodore Kim and Markus H. Gross and Barbara Solenthaler},
  journal       = {CoRR},
  title         = {Deep Fluids: {A} Generative Network for Parameterized Fluid Simulations},
  year          = {2018},
  volume        = {abs/1806.02071},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1806-02071.bib},
  eprint        = {1806.02071},
  file          = {:KimEtAl_2019_DeepFluids.pdf:PDF},
  groups        = {Neural Networks},
  timestamp     = {2020.06.30},
  url           = {http://arxiv.org/abs/1806.02071},
}

@Article{Lui2019,
  author    = {Hugo F. S. Lui and William R. Wolf},
  journal   = {Journal of Fluid Mechanics},
  title     = {Construction of reduced-order models for fluid flows using deep feedforward neural networks},
  year      = {2019},
  pages     = {963-994},
  volume    = {872},
  file      = {:LuiEtAl_2019_ROMFluidFlowsDeepFFNN.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Navratil2019,
  author    = {Jiř{\'i} Navratil and Alan King and Jes{\'u}s R{\'i}os and Georgios Kollias and Ruben Rodriguez Torrado and Andres Codas},
  journal   = {Frontiers Big Data},
  title     = {Accelerating Physics-Based Simulations Using End-to-End Neural Network Proxies: An Application in Oil Reservoir Modeling},
  year      = {2019},
  pages     = {33},
  volume    = {2},
  file      = {:NavratilEtAl_2019_PhysicsBasedSimulationsNeuralNetworkOilReservoir.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Schmidhuber2015,
  author    = {J{\"u}rgen Schmidhuber},
  journal   = {Neural networks : the official journal of the International Neural Network Society},
  title     = {Deep learning in neural networks: An overview},
  year      = {2015},
  pages     = {85-117},
  volume    = {61},
  file      = {:Schmidhuber_2014_DeepLearningNeuralNetworks.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Wang2017,
  author    = {Jian-Xun Wang and Jin-long Wu and Heng Xiao},
  journal   = {arXiv: Fluid Dynamics},
  title     = {Physics-informed machine learning approach for reconstructing Reynolds stress modeling discrepancies based on DNS data},
  year      = {2017},
  pages     = {034603},
  volume    = {2},
  file      = {:WangEtAl_2017_PhysicsInformedMLApproachReynoldsStressModelingDNSData.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Kutz2017,
  author    = {Kutz, J.},
  journal   = {Journal of Fluid Mechanics},
  title     = {Deep learning in fluid dynamics},
  year      = {2017},
  month     = {03},
  pages     = {1-4},
  volume    = {814},
  doi       = {10.1017/jfm.2016.803},
  file      = {:Kutz_2017_DeepLearningFluidDynamics.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Lye2020,
  author    = {Kjetil O. Lye and Siddhartha Mishra and Deep Ray},
  journal   = {Journal of Computational Physics},
  title     = {Deep learning observables in computational fluid dynamics},
  year      = {2020},
  issn      = {0021-9991},
  pages     = {109339},
  volume    = {410},
  abstract  = {Many large scale problems in computational fluid dynamics such as uncertainty quantification, Bayesian inversion, data assimilation and PDE constrained optimization are considered very challenging computationally as they require a large number of expensive (forward) numerical solutions of the corresponding PDEs. We propose a machine learning algorithm, based on deep artificial neural networks, that predicts the underlying input parameters to observable map from a few training samples (computed realizations of this map). By a judicious combination of theoretical arguments and empirical observations, we find suitable network architectures and training hyperparameters that result in robust and efficient neural network approximations of the parameters to observable map. Numerical experiments are presented to demonstrate low prediction errors for the trained network networks, even when the network has been trained with a few samples, at a computational cost which is several orders of magnitude lower than the underlying PDE solver. Moreover, we combine the proposed deep learning algorithm with Monte Carlo (MC) and Quasi-Monte Carlo (QMC) methods to efficiently compute uncertainty propagation for nonlinear PDEs. Under the assumption that the underlying neural networks generalize well, we prove that the deep learning MC and QMC algorithms are guaranteed to be faster than the baseline (quasi-) Monte Carlo methods. Numerical experiments demonstrating one to two orders of magnitude speed up over baseline QMC and MC algorithms, for the intricate problem of computing probability distributions of the observable, are also presented.},
  doi       = {https://doi.org/10.1016/j.jcp.2020.109339},
  file      = {:LyeEtAl_2019_DeepLearningObservablesCFD.pdf:PDF},
  groups    = {Neural Networks},
  keywords  = {CFD, Deep learning, UQ, Neural networks, Observables, Quasi-Monte Carlo},
  timestamp = {2020.06.30},
  url       = {http://www.sciencedirect.com/science/article/pii/S0021999120301133},
}

@Article{Mohan2018,
  author    = {Arvind Mohan and Datta V. Gaitonde},
  journal   = {arXiv: Computational Physics},
  title     = {A Deep Learning based Approach to Reduced Order Modeling for Turbulent Flow Control using LSTM Neural Networks},
  year      = {2018},
  file      = {:MohanEtAl_2018_DeepLearningROMTurbulentFlowControlLSTMNN.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Raissi2018,
  author    = {Maziar Raissi and Zhicheng Wang and Michael S. Triantafyllou and George Em Karniadakis},
  journal   = {ArXiv},
  title     = {Deep Learning of Vortex Induced Vibrations},
  year      = {2018},
  volume    = {abs/1808.08952},
  file      = {:RaissiEtAl_2019_DeepLearningVortexInducedVibrations.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Wang2018,
  author    = {Wang, Z. and Xiao, D. and Fang, F. and Govindan, R. and Pain, C. C. and Guo, Y.},
  journal   = {International Journal for Numerical Methods in Fluids},
  title     = {Model identification of reduced order fluid dynamics systems using deep learning},
  year      = {2018},
  number    = {4},
  pages     = {255-268},
  volume    = {86},
  abstract  = {Summary This paper presents a novel model reduction method: deep learning reduced order model, which is based on proper orthogonal decomposition and deep learning methods. The deep learning approach is a recent technological advancement in the field of artificial neural networks. It has the advantage of learning the nonlinear system with multiple levels of representation and predicting data. In this work, the training data are obtained from high fidelity model solutions at selected time levels. The long short-term memory network is used to construct a set of hypersurfaces representing the reduced fluid dynamic system. The model reduction method developed here is independent of the source code of the full physical system. The reduced order model based on deep learning has been implemented within an unstructured mesh finite element fluid model. The performance of the new reduced order model is evaluated using 2 numerical examples: an ocean gyre and flow past a cylinder. These results illustrate that the CPU cost is reduced by several orders of magnitude whilst providing reasonable accuracy in predictive numerical modelling.},
  doi       = {10.1002/fld.4416},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/fld.4416},
  file      = {:WangEtAl_2017_ModelIdentificationReducedOrderFluidDyanmicsSystemsDL.pdf:PDF},
  groups    = {Neural Networks},
  keywords  = {deep learning, LSTM, POD, ROM},
  timestamp = {2020.06.30},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/fld.4416},
}

@Article{Dosovitskiy2015,
  author    = {Alexey Dosovitskiy and Philipp Fischer and Eddy Ilg and Philip H{\"a}usser and Caner Hazirbas and Vladimir Golkov and Patrick van der Smagt and Daniel Cremers and Thomas Brox},
  journal   = {2015 IEEE International Conference on Computer Vision (ICCV)},
  title     = {FlowNet: Learning Optical Flow with Convolutional Networks},
  year      = {2015},
  pages     = {2758-2766},
  file      = {:DosovitskiyEtAl_FlowNet.pdf:PDF},
  groups    = {Neural Networks},
  timestamp = {2020.06.30},
}

@Article{Ilg2016,
  author        = {Eddy Ilg and Nikolaus Mayer and Tonmoy Saikia and Margret Keuper and Alexey Dosovitskiy and Thomas Brox},
  journal       = {CoRR},
  title         = {FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks},
  year          = {2016},
  volume        = {abs/1612.01925},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/IlgMSKDB16.bib},
  eprint        = {1612.01925},
  file          = {:IlgEtAl_FlowNet2.pdf:PDF},
  groups        = {Neural Networks},
  timestamp     = {2020.06.30},
  url           = {http://arxiv.org/abs/1612.01925},
}

@Comment{jabref-meta: databaseType:bibtex;}
